name: Update Civic Data

on:
  schedule:
    # Run monthly on the 1st at 6 AM UTC (10 PM PST previous day)
    - cron: '0 6 1 * *'
  workflow_dispatch:
    # Allow manual trigger from GitHub UI
    inputs:
      skip_pr:
        description: 'Skip creating PR (just run scraper)'
        type: boolean
        default: false
      include_blocked:
        description: 'Include blocked sites (uses Playwright, slower)'
        type: boolean
        default: false

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v6

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install Playwright (if needed)
        if: inputs.include_blocked
        run: |
          npm install playwright
          npx playwright install chromium

      - name: Run CivicPlus scraper
        run: node scripts/scrape-civicplus-councils.cjs
        continue-on-error: true

      - name: Run Granicus scraper
        run: node scripts/scrape-granicus-councils.cjs
        continue-on-error: true

      - name: Run ProudCity scraper
        run: node scripts/scrape-proudcity-councils.cjs
        continue-on-error: true

      - name: Run Wikipedia scraper
        run: node scripts/scrape-wikipedia-councils.cjs --skip-photos
        continue-on-error: true

      - name: Run Blocked Sites scraper (Playwright)
        if: inputs.include_blocked
        run: node scripts/scrape-blocked-councils.cjs
        continue-on-error: true

      - name: Generate Swift code
        run: |
          node scripts/generate-swift-from-civicplus.cjs > /tmp/swift-output.swift 2>&1 || true

      - name: Check for changes
        id: changes
        run: |
          git add data-exports/city-councils/*.json || true
          git add public/images/officials/ || true
          if git diff --cached --quiet; then
            echo "has_changes=false" >> "$GITHUB_OUTPUT"
          else
            echo "has_changes=true" >> "$GITHUB_OUTPUT"
          fi

      - name: Generate summary
        if: steps.changes.outputs.has_changes == 'true'
        run: |
          echo "## Civic Data Update Summary" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"

          # Count data from all sources
          for file in data-exports/city-councils/*-data.json; do
            if [ -f "$file" ]; then
              source=$(basename "$file" -data.json)
              stats=$(cat "$file" | node -e "
                const data = JSON.parse(require('fs').readFileSync('/dev/stdin', 'utf8'));
                let total = 0, cities = 0;
                for (const city of Object.values(data)) {
                  if (city.officials && city.officials.length > 0) {
                    cities++;
                    total += city.officials.length;
                  }
                }
                console.log(cities + ' cities, ' + total + ' officials');
              ")
              echo "- **${source}:** ${stats}" >> "$GITHUB_STEP_SUMMARY"
            fi
          done

          echo "" >> "$GITHUB_STEP_SUMMARY"
          echo "### Downloaded Photos" >> "$GITHUB_STEP_SUMMARY"
          photo_count=$(find public/images/officials -name "*.jpg" 2>/dev/null | wc -l | tr -d ' ')
          echo "- **Photos:** ${photo_count}" >> "$GITHUB_STEP_SUMMARY"

      - name: Create Pull Request
        if: steps.changes.outputs.has_changes == 'true' && !inputs.skip_pr
        uses: peter-evans/create-pull-request@v5
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          commit-message: 'chore: Update civic data from scrapers'
          title: 'üèõÔ∏è Monthly Civic Data Update'
          body: |
            ## Automated Civic Data Update

            This PR was automatically generated by the civic data scraper workflow.

            ### Sources scraped
            - CivicPlus (~45 cities)
            - Granicus OpenCities (~12 cities)
            - ProudCity/WordPress (~9 cities)
            - Wikipedia (fallback for ~40 cities)
            ${{ inputs.include_blocked && '- Blocked sites via Playwright (~19 cities)' || '' }}

            ### What changed
            - Updated city council member data from Bay Area city websites
            - Downloaded new official photos (if available)
            - Updated JSON data files in `data-exports/city-councils/`

            ### Next steps
            1. Review the scraped data for accuracy
            2. Run `node scripts/generate-swift-from-civicplus.cjs` to see Swift output
            3. Manually update `CivicService.swift` if needed
            4. Merge when ready

            ---
            *This PR was generated by the [update-civic-data](.github/workflows/update-civic-data.yml) workflow.*
          branch: civic-data-update
          delete-branch: true
          labels: |
            automated
            civic-data

      - name: Upload scraped data artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: civic-data
          path: |
            data-exports/city-councils/*.json
            /tmp/swift-output.swift
          retention-days: 30
